#random.seed=1234567
run.name=rlsate1-plastic-risi
run.reset=true
num.runs=1

###########
# evolution
###########
num.runs=30
num.generations=2000
popul.size=1000

performance.target=1
performance.target.type=higher
# If greater than 1 then use an average of the best performance over this many generations.
performance.target.average=10

#false means mutation probabilities are applied to all possible places a mutation could occur
#true means probabilities apply to individual as a whole; only one topological mutation can occur per individual
#note that this applies only to topological mutations, not weight mutations
topology.mutation.classic=true

#classic=[0.01, 0.5], not classic=[0.0001,] dependent on pop size. 0.03
add.neuron.mutation.rate=0.05

# Mutation rate for operator that adds neurons anywhere in the network (as 
# opposed to regular add neuron operator that only adds them in place of 
# existing connections). Only works for topology.mutation.classic=false
add.neuron.anywhere.mutation.rate=0.0

#classic=[0.01, 0.5], not classic=[0.0001,] dependent on pop size. 0.4
add.connection.mutation.rate=0.1
#[0.01, 0.3]
remove.connection.mutation.rate=0.01
#only remove weights with magnitude smaller than this
remove.connection.max.weight=1000

#should be 1.0
prune.mutation.rate=1.0

#[0.1, 0.8]
weight.mutation.rate=0.8
#[1.0, 2.0] dependent on (CPPN) weight.max/min?
weight.mutation.std.dev=1
# The amount to perturb weights by when generating the initial population. Default is weight.mutation.std.dev
#weight.mutation.std.dev.initial=0.01

#percent of individuals used as parents
survival.rate=0.1
#proportion of sexual (crossover) versus asexual reproduction.
crossover.proportion=0.5
# the probability that an individual produced by the crossover operator will be a candidate for having mutations applied to it (independent of other mutation probabilities).
crossover.mutate.probability=0

#[1, 5]
selector.elitism.min.specie.size=0
#percent of individuals from each species copied to next generation unchanged
selector.elitism.proportion=0.1
#min number to select from a species (if it has size >=  selector.elitism.min.specie.size)
selector.elitism.min.to.select=0
selector.roulette=false
selector.min.generations=0
selector.max.stagnant.generations=400
selector.speciated.fitness=true


############
# speciation
############
#species distance factors
#c1, excess genes factor [1.0, 2.0]
chrom.compat.excess.coeff=2
#c2, disjoint genes factor [1.0, 2.0]
chrom.compat.disjoint.coeff=2
#c3, Weight difference factor [0.2, 3.0]
chrom.compat.common.coeff=1.0

#compatability threshold [0.1, 4.0], relative to c#
speciation.threshold=2.3
speciation.target=20
speciation.threshold.change=0.05


##################
# fitness function
##################
fitness_function.class=com.ojcoleman.ahni.experiments.RLStateBased
#max threads to use for fitness evaluation (including transcription of genotype/cppn to phenotype/substrate)
#if value is <= 0 then the detected number of processor cores will be used
fitness.max_threads=0

fitness.function.multi.class=com.ojcoleman.ahni.evaluation.mocostfunctions.BainNNConnectionCountCost
fitness.function.multi.weighting=0.9999, 0.0001
fitness.function.multi.probability=1

#experiment specific

#The number of environments to evaluate candidates against. Increasing this will provide a more accurate evaluation but take longer.
fitness.function.rlstate.environment.count=25
#The fraction of environments that should be replaced with new environments per generation. This is evaluated probabilistically.
fitness.function.rlstate.environment.replacerate=0.05

#The initial number of states in the generated environments.
fitness.function.rlstate.states.initial=4
#The maximum amount to increase the number of states in the generated environments to.
fitness.function.rlstate.states.maximum=4
#The amount to increase the number of states in the generated environments when the current size has been sufficiently mastered.
#If the value is followed by an "x" then the value is considered a factor (and so should be > 1).
fitness.function.rlstate.states.delta=0

#The initial number of actions available in the generated environments.
fitness.function.rlstate.actions.initial=2
#The maximum amount to increase the available number of actions in the generated environments to.
fitness.function.rlstate.actions.maximum=2
#The amount to increase the available number of actions in the generated environments when the current size has been sufficiently mastered (see {@link #DIFFICULTY_INCREASE_PERFORMANCE}.
#the value is followed by an "x" then the value is considered a factor (and so should be > 1).
fitness.function.rlstate.actions.delta=0

#The performance indicating when the environment size/difficulty should be increased as the current size has been sufficiently mastered. Performance is calculated
#as a proportion of the maximum possible fitness (which is the sum of reward received over all trials in all environments).
fitness.function.rlstate.difficulty.increase.performance=0.9

#The proportion of actions that will map to some other state. This is evaluated probabilistically for all states and actions when generating an environment.
fitness.function.rlstate.action.map.ratio=0
#The proportion of states that will contain a reward value greater than 0. A value of 0 will force only 1 state to have a reward.
fitness.function.rlstate.states.reward.ratio=0


################
# CPPN/AnjiNet #
################
#input and output size determined by hyperneat settings
#stimulus.size=7
#response.size=1
initial.topology.activation=random
initial.topology.fully.connected=true
initial.topology.num.hidden.neurons=0
initial.topology.activation.input=linear
# Using an activation function with range [0, 1] or [-1, 1] causes the transcriber to scale the output to the substrate weight range, rather than truncating it to that range.
initial.topology.activation.output=linear
initial.topology.activation.random.allowed=absolute, sigmoid, gaussian, sine
#initial.topology.activation.random.probabilities=0.2, 1, 0.5, 0.5, 0.2, 0.1

recurrent=disallowed
recurrent.cycles=1
#[1, 500]
#weight.min=-20
weight.max=10


#####################
# HyperNEAT/BainNN #
#####################
ann.transcriber.class=com.ojcoleman.ahni.transcriber.HyperNEATTranscriberBain
#ann.transcriber.class=com.ojcoleman.ahni.transcriber.ESHyperNEATTranscriberBain
#ann.transcriber.bain.maxrecurrentcyclesearchlength=20
ann.transcriber.bain.executionmode=SEQ

ann.transcriber.neuron.model=com.ojcoleman.bain.neuron.rate.RisiModulatoryNeuronCollection
ann.transcriber.synapse.model=com.ojcoleman.bain.synapse.rate.RisiModulatorySynapseCollection
#ann.transcriber.neuron.model=com.ojcoleman.bain.neuron.rate.SigmoidBipolarNeuronCollection
#ann.transcriber.synapse.model=com.ojcoleman.bain.synapse.rate.FixedSynapseCollection

# Create CPPN outputs that set the parameters for each neuron.
ann.transcriber.neuron.model.params=modBias
# Min and max values for model parameters.
ann.transcriber.neuron.model.params.min=-100
ann.transcriber.neuron.model.params.max=100
ann.transcriber.neuron.model.params.expression.threshold=0.2

# Create CPPN outputs that set the parameters for each synapse.
ann.transcriber.synapse.model.params=n,a,b,c
# Min and max values for model parameters.
ann.transcriber.synapse.model.params.min=-100,-1,-1,-1
ann.transcriber.synapse.model.params.max=100,1,1,1
ann.transcriber.synapse.model.params.expression.threshold=0.2,0.05,0.05,0.05
# Two synapse types: regular = 0, modulatory = 1
# Separate weight outputs from CPPN will be used for each type. 
ann.transcriber.synapse.model.types=modulatory,0,1
# This parameter in the synapse model will be set to 0 if the connection should not be expressed. This is typically applied to a "learning rate" parameter.
ann.transcriber.synapse.model.plasticitydisableparam=n

ann.hyperneat.feedforward=true
#For networks with recurrent connections, the number of activation cycles to perform each time the substrate network is presented with new input and queried for its output. 
ann.hyperneat.cyclesperstep=2
ann.hyperneat.enablebias=true
ann.hyperneat.includedelta=true
ann.hyperneat.includeangle=false
ann.hyperneat.useinputlayerencoding=true

ann.hyperneat.connection.expression.threshold=0.2
ann.hyperneat.leo=true

#ann.transcriber.connection.weight.min=-2
ann.transcriber.connection.weight.max=100

ann.hyperneat.depth=3
# input and output layer dimensions determined by fitness function
ann.hyperneat.width=f,4,f
ann.hyperneat.height=f,1,f

ann.hyperneat.range.x=-1,1
ann.hyperneat.range.y=-1,1
ann.hyperneat.range.z=-1,1


# ES-HyperNEAT params (ONLY FOR ann.transcriber.class=com.ojcoleman.ahni.transcriber.ESHyperNEATTranscriberBain)
ann.eshyperneat.iterations=1
ann.eshyperneat.depth.initial=1
ann.eshyperneat.depth.max=2
ann.eshyperneat.division.threshold=0.5
ann.eshyperneat.variance.threshold=0.03
ann.eshyperneat.band.threshold=0.3

# Record the coordinates of neurons in the substrate. This allows for rendering the network.
ann.eshyperneat.record.coordinates=true

# If true then the substrate is considered as occupying a 3D space, with the 
# inputs and outputs located on the XY plane at z=0 and z=1 respectively, and
# hidden neurons located on the XZ plane at y=0.5 (with respect to a unit-size hypercube).
# If false then all neurons are located in a 2D plane with X-Y axes.
ann.eshyperneat.3D.pseudo=true


#############
# persistence
#############
persistence.class=com.anji.persistence.FilePersistence
persistence.base.dir=./db
persist.enable=false
persist.all=false
persist.champions=false
persist.last=false
persist.load.genotype=false
id.file=./db/id.xml
neat.id.file=./db/neatid.xml

##############
# presentation
##############
presentation.generate=false
presentation.dir=./nevt

#########
# logging
#########
# How often to produce a line in the log containing a brief summary of the current progress.
log.pergenerations=1

# FileAppenders with the name RunLog receive special treatment: for each run the output will be directed to a file 
# with the name specified by log4j.appender.RunLog.File in the directory [output.dir]/[run number]/
#log4j.rootLogger=INFO, C, RunLog
log4j.rootLogger=INFO, C, RunLog
log4j.appender.C=org.apache.log4j.ConsoleAppender
log4j.appender.RunLog=org.apache.log4j.FileAppender
log4j.appender.RunLog.File=log.txt
log4j.appender.C.layout=org.apache.log4j.PatternLayout
log4j.appender.RunLog.layout=org.apache.log4j.PatternLayout
log4j.appender.C.layout.ConversionPattern=%-5p %m%x%n
log4j.appender.RunLog.layout.ConversionPattern=%-5p %m%x%n

################
# other output #
################
output.dir=../rlsate1-plastic-risi
# Whether to log the champ to a text file and/or image. N < 0 indicates no logging, N=0 indicates 
# only at the end of evolution, N > 0 indicates every N generations and after evolution has finished.
log.champ.tostring=25
log.champ.toimage=-1
log.champ.evaluation=25


#######################################
# parameter tuning via ParameterTuner #
#######################################

parametertuner.totune=       add.neuron.mutation.rate, add.neuron.anywhere.mutation.rate, add.connection.mutation.rate, weight.mutation.rate, weight.mutation.std.dev
parametertuner.initialvalues=0.001,                    0.001,                             0.0015,                       0.5,                  0.5
parametertuner.minvalues=    0,                        0,                                 0,                            0,                    0.01
parametertuner.maxvalues=    1,                        1,                                 1,                            1,                    100
parametertuner.initialvalueadjustfactor=2
parametertuner.numruns=100
parametertuner.numgens=500
parametertuner.solvedperformance=0.98
parametertuner.htcondor=\
  executable = ../ahni.jar \n \
  jar_files = ../ahni.jar
