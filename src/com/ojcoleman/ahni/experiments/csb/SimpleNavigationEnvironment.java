package com.ojcoleman.ahni.experiments.csb;

import java.awt.Color;
import java.awt.Graphics2D;
import java.util.Arrays;
import java.util.BitSet;
import java.util.Random;
import java.util.Vector;

import org.apache.commons.lang3.ArrayUtils;
import org.apache.commons.math3.linear.ArrayRealVector;
import org.apache.commons.math3.util.MultidimensionalCounter;
import org.apache.log4j.Logger;

import com.ojcoleman.ahni.hyperneat.Properties;
import com.ojcoleman.ahni.util.ArrayUtil;

/**
 * <p>
 * Implements an environment that essentially represents a simple navigation like task. The agent perceives the current
 * state as is (no transformation is performed between the environments current state and the agents perception of it).
 * The agent can directly move around within the Cartesian space represented by the environment state space: the agents
 * output is interpreted as a motion vector which changes the current state in a linear additive way. The reward signal,
 * which is the Euclidean distance from the current environment state to the goal state, is provided directly to the
 * agent.
 * </p>
 * <p>
 * Environments can optionally have (hyper-)spherical obstacles added at random locations (increasing the environment
 * difficulty increases the number of obstacles). The agent cannot directly perceive the obstacles. If the environment
 * size (dimensionality) is 2 then the images generated by RLContinuousStateBased will include the obstacle locations.
 * </p>
 */
public class SimpleNavigationEnvironment extends Environment {
	private static Logger logger = Logger.getLogger(SimpleNavigationEnvironment.class);

	/**
	 * The initial number of obstacles that should be included. Default is 0.
	 */
	public static final String OBSTACLE_COUNT_INITIAL = "fitness.function.rlcss.obstacles.initial";
	/**
	 * The amount to increase the obstacle count when environments with the current value have been sufficiently
	 * mastered (see {@link RLContinuousStateBased#DIFFICULTY_INCREASE_PERFORMANCE}. If the value is followed by an "x" then the value is
	 * considered a factor (and so should be > 1). Default is 1.
	 */
	public static final String OBSTACLE_COUNT_INCREASE_DELTA = "fitness.function.rlcss.obstacles.delta";
	/**
	 * The maximum amount to increase the obstacle count to. Default is lots.
	 */
	public static final String OBSTACLE_COUNT_MAX = "fitness.function.rlcss.obstacles.maximum";

	private int obstacleCount;
	ArrayRealVector[] obstacleLocation;
	double[] obstacleRadius;
	int requiredSteps = 0;
	double maxStepSize = 0.1;

	@Override
	public void init(Properties props) {
		super.init(props);

		obstacleCount = props.getIntProperty(OBSTACLE_COUNT_INITIAL, 0);
	}

	@Override
	public void setUp(int id) {
		this.id = id;
		Random random = props.getEvolver().getConfig().getRandomGenerator();

		// Start state is in randomly selected corner.
		startState = new ArrayRealVector(size);
		for (int i = 0; i < size; i++) {
			//startState.setEntry(i, (random.nextBoolean() ? 0 : 0.9) + random.nextDouble() * 0.1);
			startState.setEntry(i, random.nextDouble());
		}

		// Goal state is in randomly selected location with minimum distance of 1 from start state.
		goalState = new ArrayRealVector(size);
		do {
			for (int i = 0; i < size; i++) {
				goalState.setEntry(i, random.nextDouble());
			}
		} while (goalState.getDistance(startState) < 0.2);

		obstacleLocation = new ArrayRealVector[obstacleCount];
		obstacleRadius = new double[obstacleCount];
		double path = 0;
		double radius = 0.3;
		for (int o = 0; o < obstacleCount; o++) {
			// obstacleRadius[o] = random.nextDouble() * 0.3 + 0.1;
			obstacleRadius[o] = radius;
			boolean validPlacement = false;
			int attempts = 0;
			do {
				obstacleLocation[o] = new ArrayRealVector(ArrayUtil.newRandom(size, random), false);
				path = findPath();
				validPlacement = !collision(o, startState) && !collision(o, goalState) && path != -1;

				if (!validPlacement) {
					// Keep shrinking radius until we can make it fit.
					radius *= 0.95;
					attempts++;
				}

				// If we can't seem to find anywhere to put this obstacle, start all over again.
				// This should never happen, but it did at least once...
				if (attempts == 1000) {
					logger.warn("Couldn't seem to find anywhere to put obstacle " + o + ", restarting obstacle placements.");
					o = -1;
					radius = 0.3;
					break;
				}
			} while (!validPlacement);
		}
		if (obstacleCount == 0) {
			path = findPath();
		}
		requiredSteps = (int) Math.round((path*2) / maxStepSize);
	}

	@Override
	public void updateStateAndOutput(ArrayRealVector state, double[] input, double[] output) {
		// Update state given input.
		ArrayRealVector newState = state.copy();
		double[] newStateData = newState.getDataRef();
		double[] stateData = state.getDataRef();
		for (int i = 0; i < stateData.length; i++) {
			newStateData[i] = Math.min(1, Math.max(0, stateData[i] + input[i] * maxStepSize));
		}

		// Determine if a collision has occurred with any obstacle.
		for (int o = 0; o < obstacleCount; o++) {
			// If collision occurs then disallow the move (state does not change).
			if (collision(o, newState)) {
				return;
			}
		}
		state.setSubVector(0, newState);

		// Update state internally. Nothing to do for now.

		// Update output given new state.
		getOutputForState(state, output);
	}

	@Override
	public void getOutputForState(ArrayRealVector state, double[] output) {
		// Update output given new state.
		System.arraycopy(state.getDataRef(), 0, output, 0, state.getDimension());
		if (state.equals(startState)) {
			// Set reward signal to -1 to indicate that the agent is in the start state,
			// and so a new trial and/or environment has been entered.
			output[output.length - 1] = -1;
		} else {
			output[output.length - 1] = 1 - state.getDistance(goalState) / Math.sqrt(size);
		}
	}

	private boolean collision(int o, ArrayRealVector p) {
		if (obstacleLocation[o] == null)
			return false;
		return p.getDistance(obstacleLocation[o]) <= obstacleRadius[o];
	}

	// Returns the length (in terms of minimum steps) of the approximate shortest path through the environment, or -1 if
	// no path was found.
	// The returned length represents an upper bound due to the path following a uniform grid within the space (taxicab
	// geometry).
	// TODO Use sampling method when size (number of dimensions) > 5 or so (also dependent on maxStepSize but to a less
	// extent, could base decision on pointCount).
	private double findPath() {
		int granularity = (int) Math.ceil(1 / maxStepSize) + 1;
		double stepSize = 1.0 / (granularity - 1);
		int pointCount = (int) Math.pow(granularity, size);
		BitSet obstacleOccludes = new BitSet(pointCount);
		MultidimensionalCounter mc = new MultidimensionalCounter(ArrayUtil.newArray(size, granularity));

		// Determine which points are occluded by obstacles. This is probably not a particularly efficient
		// implementation.
		ArrayRealVector pointARV = new ArrayRealVector(size);
		double[] point = pointARV.getDataRef();
		MultidimensionalCounter.Iterator mci = mc.iterator();
		// For each point in the grid.
		for (int i = 0; i < pointCount; i++) {
			int idx = mci.next();
			for (int d = 0; d < size; d++)
				point[d] = mci.getCount(d) * stepSize;

			for (int o = 0; o < obstacleCount; o++) {
				if (collision(o, pointARV)) {
					obstacleOccludes.set(idx);
					break;
				}
			}
		}

		// Seed start and goal covered and front sets with corresponding closest points in grid.
		BitSet startCovered = new BitSet(pointCount); // Record which points have been covered in search emanating from
														// start state.
		Vector<Point> startFront = new Vector<Point>(); // List of indices corresponding to current search front
														// emanating from start state.
		int[] sfIndices = new int[size];
		for (int d = 0; d < size; d++)
			sfIndices[d] = (int) Math.floor(startState.getEntry(d) * granularity);
		int idx = mc.getCount(sfIndices);
		startCovered.set(idx);
		startFront.add(new Point(sfIndices, idx));

		BitSet goalCovered = new BitSet(pointCount); // Record which points have been covered in search emanating from
														// goal state.
		Vector<Point> goalFront = new Vector<Point>(); // List of indices corresponding to current search front
														// emanating from goal state.
		int[] gfIndices = new int[size];
		for (int d = 0; d < size; d++)
			gfIndices[d] = (int) Math.floor(goalState.getEntry(d) * granularity);
		idx = mc.getCount(gfIndices);
		goalCovered.set(idx);
		goalFront.add(new Point(gfIndices, idx));

		// Iteratively expand start and goal fronts until they meet or can no longer be expanded.
		Vector<Point> startFrontNext = new Vector<Point>(), goalFrontNext = new Vector<Point>();
		int[] indexOffsets = new int[size];
		for (int d = 0; d < size; d++)
			indexOffsets[d] = (int) Math.pow(granularity, size - d - 1);
		int length = 1;
		do {
			// Expand start front, check if it meets goal front.
			for (Point p : startFront) {
				for (int d = 0; d < size; d++) {
					for (int offset = -1; offset <= 1; offset += 2) {
						int newCoord = p.indices[d] + offset;
						if (newCoord >= 0 && newCoord < granularity) {
							int neighbourIndex = p.index + offset * indexOffsets[d];
							if (!obstacleOccludes.get(neighbourIndex)) {
								if (goalCovered.get(neighbourIndex)) {
									return length * stepSize;
								}
								if (!startCovered.get(neighbourIndex)) {
									startCovered.set(neighbourIndex);
									Point neighbour = new Point(ArrayUtils.clone(p.indices), neighbourIndex);
									neighbour.indices[d] = newCoord;
									startFrontNext.add(neighbour);
								}
							}
						}
					}
				}
			}

			length++;

			// Expand goal front, check if it meets start front.
			for (Point p : goalFront) {
				for (int d = 0; d < size; d++) {
					for (int offset = -1; offset <= 1; offset += 2) {
						int newCoord = p.indices[d] + offset;
						if (newCoord >= 0 && newCoord < granularity) {
							int neighbourIndex = p.index + offset * indexOffsets[d];
							if (!obstacleOccludes.get(neighbourIndex)) {
								if (startCovered.get(neighbourIndex)) {
									return length * stepSize;
								}
								if (!goalCovered.get(neighbourIndex)) {
									goalCovered.set(neighbourIndex);
									Point neighbour = new Point(ArrayUtils.clone(p.indices), neighbourIndex);
									neighbour.indices[d] = newCoord;
									goalFrontNext.add(neighbour);
								}
							}
						}
					}
				}
			}

			length++;

			Vector<Point> t = startFront;
			startFront = startFrontNext;
			startFrontNext = t;
			startFrontNext.clear();
			t = goalFront;
			goalFront = goalFrontNext;
			goalFrontNext = t;
			goalFrontNext.clear();

			// If one of the fronts could not be expanded (and they have not yet met), then it means
			// that they are entirely surrounded by obstacles and/or the edge of the environment space.
		} while (!startFront.isEmpty() && !goalFront.isEmpty());

		return -1;
	}

	@Override
	public boolean increaseDifficultyPossible() {
		return getNewObstacleCount() > obstacleCount;
	}

	@Override
	public void increaseDifficulty() {
		obstacleCount = getNewObstacleCount();
	}

	private int getNewObstacleCount() {
		int obstacleCountMax = props.getIntProperty(OBSTACLE_COUNT_MAX);
		if (obstacleCount == obstacleCountMax) {
			return obstacleCount;
		}

		int newObstacleCount = obstacleCount;
		String deltaString = props.getProperty(OBSTACLE_COUNT_INCREASE_DELTA).trim().toLowerCase();
		boolean isFactor = deltaString.endsWith("x");
		double delta = Double.parseDouble(deltaString.replaceAll("x", ""));
		if (delta >= 1) {
			if (!isFactor) {
				newObstacleCount = obstacleCount + (int) Math.round(delta);
			} else if (delta > 1) {
				newObstacleCount = (int) Math.round(obstacleCount * delta);
			}
			if (newObstacleCount > obstacleCountMax) {
				newObstacleCount = obstacleCountMax;
			}
		}
		return newObstacleCount;
	}

	@Override
	public int getMinimumStepsToSolve() {
		return requiredSteps;
	}

	@Override
	public void logToImage(Graphics2D g, int imageSize) {
		// Draw obstacles.
		g.setColor(Color.GRAY);
		for (int o = 0; o < obstacleCount; o++) {
			if (obstacleLocation[o] != null) {
				int x = (int) Math.round((obstacleLocation[o].getEntry(0) - obstacleRadius[o]) * imageSize);
				int y = (int) Math.round((obstacleLocation[o].getEntry(1) - obstacleRadius[o]) * imageSize);
				int diameter = (int) Math.round(obstacleRadius[o] * 2 * imageSize);
				g.fillOval(x, y, diameter, diameter);
			}
		}
	}

	private static class Point {
		public int[] indices;
		int index;

		public Point(int[] indices, int index) {
			this.indices = indices;
			this.index = index;
		}

		public String toString() {
			return "Point " + index + " (" + Arrays.toString(indices) + ")";
		}
	}
}