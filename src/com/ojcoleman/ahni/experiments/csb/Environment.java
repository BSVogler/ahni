package com.ojcoleman.ahni.experiments.csb;

import java.awt.Graphics2D;
import java.util.Random;

import org.apache.commons.math3.linear.ArrayRealVector;
import org.jgapcustomised.Chromosome;

import com.ojcoleman.ahni.evaluation.novelty.Behaviour;
import com.ojcoleman.ahni.evaluation.novelty.NoveltySearch;
import com.ojcoleman.ahni.hyperneat.Configurable;
import com.ojcoleman.ahni.hyperneat.Properties;
import com.ojcoleman.ahni.util.ArrayUtil;

public abstract class Environment implements Configurable  {
	/**
	 * The size of the output vector. Defaults to fitness.function.rlcss.size + 1. 
	 * This will always be at least one to allow the agent to observe at least the node representing the reward value.
	 */
	//public static final String OUTPUT_SIZE = "fitness.function.rlcss.size.output";
	/**
	 * The size of the input vector. Defaults to fitness.function.rlcss.size. 
	 */
	//public static final String INPUT_SIZE = "fitness.function.rlcss.size.input";

	
	Properties props;
	/**
	 * The containing RLContinuousStateBased object.
	 */
	protected RLContinuousStateBased rlcss;
	protected int size;
	protected int outputSize;
	protected int inputSize;
	protected int id;
	protected ArrayRealVector startState;
	protected ArrayRealVector goalState;
	
	@Override
	public void init(Properties props) {
		this.props = props;
		size = props.getIntProperty(RLContinuousStateBased.SIZE);
		//outputSize = Math.max(1, props.getIntProperty(OUTPUT_SIZE, size));
		//inputSize = Math.max(1, props.getIntProperty(INPUT_SIZE, size+1));
		outputSize = size+1;
		inputSize = size;

		if (outputSize > size+1 || inputSize > size) {
			throw new IllegalArgumentException("The input and/or output size have been set larger than the environment size).");
		}
	}

	/**
	 * Set-up the environment configuration.
	 */
	public abstract void setUp(int id);
	
	/**
	 * This function should do three things: 
	 * (1) update the given state given the input;
	 * (2) update the given state internally if the environment is dynamic (changes even when if the agent provides no "actions"), and
	 * (3) update/set the output based on the new current state.
	 */  
	public abstract void updateStateAndOutput(ArrayRealVector state, double[] input, double[] output);
		
	/**
	 * Update/set the output based on the given state.
	 */
	public abstract void getOutputForState(ArrayRealVector state, double[] output);
	
	/**
	 * Return the minimum required steps to solve this environment instance.
	 */
	public abstract int getMinimumStepsToSolve();
	
	/**
	 * Return true iff it is possible to (further) increase the difficulty of environments of this type, eg by introducing a larger number of obstacles, a more convoluted transform between state and output, etc.
	 */
	public abstract boolean increaseDifficultyPossible();
	
	/**
	 * Adjust the variables determining difficulty to increase the difficulty of environment instances generated by this environment type.
	 * The {@link #setUp(int)} method will be called immediately after calling this method to generate a new environment instance.
	 */
	public abstract void increaseDifficulty();
	
	/**
	 * Optionally allow rendering the current environment configuration to an image. This is only called if the environment size is 2.
	 */
	public void logToImage(Graphics2D g, int imageSize) {}
}